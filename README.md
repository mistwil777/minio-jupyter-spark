# ğŸš€ MinIO + PySpark Docker Playground

I couldnâ€™t find any working MinIO + PySpark combo, so I made this **Docker playground!**

Working as of **December 2025**.

> âš ï¸ Donâ€™t forget to change the MinIO username/password in docker-compose.yml before starting.
> 

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ minio_data        # Persistent storage for MinIO
â”œâ”€â”€ notebooks         # Your Jupyter notebooks
â”œâ”€â”€ spark             # Dockerfile for PySpark environment
â””â”€â”€ docker-compose.yml

```

---

## ğŸƒ Quick Start

1ï¸âƒ£ Update MinIO credentials in `docker-compose.yml`:

```yaml
environment:
  MINIO_ROOT_USER: <your_username>
  MINIO_ROOT_PASSWORD: <your_password>

```

2ï¸âƒ£ Run Docker Compose:

```bash
docker-compose up -d

```

3ï¸âƒ£ Access your tools:

- MinIO Console: [http://localhost:9001](http://localhost:9001/) ğŸ—„ï¸
- PySpark Jupyter Lab: [http://localhost:8888](http://localhost:8888/) ğŸ“
- Spark UI: [http://localhost:4040](http://localhost:4040/) ğŸ”¥

---

## ğŸ› ï¸ Dockerfile Highlights (spark/Dockerfile)

- Installs AWS SDK & Hadoop AWS to let PySpark talk to MinIO
- Uses the latest `quay.io/jupyter/pyspark-notebook` as base

---

## ğŸ‰ License

This project is licensed under the **MIT License** â€“ totally free to use, tweak, and share.
